# LLM Project â€“ Intelligent Data Query & Analysis System

## ğŸ“Œ Project Overview
This project is a **modular LLM-based application** built using **LangChain**.
It ingests structured data, stores it in a database, and allows intelligent querying
using Large Language Models (LLMs).

The architecture is designed for **scalability, clarity, and maintainability**.

---

## ğŸ§  System Architecture & Workflow

### 1ï¸âƒ£ Data Layer
**Location:** `data/`

- `raw/` â†’ Original datasets
- `processed/` â†’ Cleaned and transformed datasets

Raw data is first processed and prepared before ingestion.

---

### 2ï¸âƒ£ Data Ingestion
**Location:** `ingestion/`

- `ingest_to_sqlite.py`  
  Reads processed data and stores it into a SQLite database.

This enables structured storage and fast retrieval for LLM-based querying.

---

### 3ï¸âƒ£ LangChain Intelligence Layer
**Location:** `langchain_layer/`

This layer manages all LLM-related logic.

- `agent/` â†’ Decision-making agents
- `chains/` â†’ LangChain chains (prompt â†’ model â†’ output)
- `intent/` â†’ User intent detection
- `orchestration/` â†’ Controls interaction between agents and chains
- `db/` â†’ Database retrieval logic

This layer converts user input into meaningful, context-aware responses.

---

### 4ï¸âƒ£ LLM Configuration
**Location:** `llm/`

Handles:
- LLM initialization
- Model configuration (Groq / OpenAI-compatible)

Keeps model logic separated from business logic.

---

### 5ï¸âƒ£ Application Execution
**Root Files:**

- `main.py` â†’ Main application logic
- `run.py` â†’ Entry point to run the full pipeline
- `demo.py` â†’ Demonstration script
- `.env` â†’ API keys and environment variables
- `requirements.txt` â†’ Project dependencies

---

## ğŸ› ï¸ Technologies Used
- Python
- LangChain
- Groq LLM
- OpenAI-compatible APIs
- SQLite
- Pandas
- Pydantic
- DuckDuckGo Search (ddgs)
- Wikipedia API

---

## âš™ï¸ Setup Instructions

1. Clone the repository:
```bash
git clone https://github.com/your-username/llm_project.git
